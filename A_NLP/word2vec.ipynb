{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation Process\n",
    "\n",
    "Data Preparation — Define corpus, clean, normalise and tokenise words\n",
    "\n",
    "Hyperparameters — Learning rate, epochs, window size, embedding size\n",
    "\n",
    "Generate Training Data — Build vocabulary, one-hot encoding for words, build dictionaries that map id to word and vice versa\n",
    "\n",
    "Model Training — Pass encoded words through forward pass, calculate error rate, adjust weights using backpropagation and compute loss\n",
    "\n",
    "Inference — Get word vector and find similar words\n",
    "Further improvements — Speeding up training time with Skip-gram Negative Sampling (SGNS) and Hierarchical Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"natural language processing and machine learning is fun and exciting\",\"I am also a good in machine learning\"]\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(len(text)):\n",
    "    corpus.append([word.lower() for word in text[i].split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'and',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'is',\n",
       "  'fun',\n",
       "  'and',\n",
       "  'exciting'],\n",
       " ['i', 'am', 'also', 'a', 'good', 'in', 'machine', 'learning']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "'window_size': 2, # context window +- center word\n",
    "'n': 10,# dimensions of word embeddings, also refer to size of hidden layer\n",
    "'epochs': 50,# number of training epochs\n",
    "'learning_rate': 0.01# learning rate\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.01 50 2\n"
     ]
    }
   ],
   "source": [
    "class word2vec():\n",
    "    def __init__(self):\n",
    "        self.n=settings['n']\n",
    "        self.lr=settings['learning_rate']\n",
    "        self.epochs=settings['epochs']\n",
    "        self.window=settings['window_size']\n",
    "        print(self.n,self.lr,self.epochs,self.window)\n",
    "\n",
    "    \n",
    "    def generate_training_data(self,settings,corpus):\n",
    "        word_counts=collections.defaultdict(int)\n",
    "        for row in corpus:\n",
    "            for word in row:\n",
    "                word_counts[word]+=1\n",
    "        \n",
    "        self.v_count=len(word_counts.keys()) #Unique words of vocabulary\n",
    "        self.words_list=list(word_counts.keys())\n",
    "        self.word_index=dict((word,i) for i,word in enumerate(self.words_list))\n",
    "        self.index_word=dict((i,word) for i,word in enumerate(self.words_list))\n",
    "\n",
    "        training_data=[]\n",
    "        \n",
    "        for sentence in corpus:\n",
    "            sent_len=len(sentence)\n",
    "            for i,word in enumerate(sentence):\n",
    "                w_target=self.wordonehot(sentence[i])\n",
    "                w_context=[]\n",
    "                for j in range(i-self.window,i+self.window+1):\n",
    "                    if j!=i and j>=0 and j<=sent_len-1:\n",
    "                        w_context.append(self.wordonehot(sentence[j]))\n",
    "                training_data.append([w_target,w_context])\n",
    "        \n",
    "        return np.array(training_data)\n",
    "           \n",
    "    def wordonehot(self,word):\n",
    "        word_vec=[0 for i in range(self.v_count)]\n",
    "        word_index=self.word_index[word]\n",
    "        word_vec[word_index]=1\n",
    "        return word_vec  \n",
    "\n",
    "    \n",
    "\n",
    "a=word2vec()\n",
    "contexts=a.generate_training_data(settings,corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
